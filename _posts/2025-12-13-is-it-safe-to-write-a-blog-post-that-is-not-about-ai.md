---
layout: post
title: Is It Safe to Write a Blog Post That Is Not About AI?
date: 2025-12-13 00:00:00
description: >
  I have a confession to make...
tags:
 - ai
 - technology
---

_Warning: Occasional pithy humor and light-hearted sarcasm ahead._

I have a confession to make...

Lately, I've been thinking about writing a blog post that is not about AI.

Is it safe to do this?

Or will it pull me further away from the Light?

![A cropped version of Michelangelo's The Creation of Adam. On the right, God reaches out from a cluster of figures, labeled "AI" in bold white Impact-style text. On the left, Adam reclines on the ground, reaching back, labeled "THE REST OF TECHNOLOGY." The two hands nearly touch, parodying the original scene to suggest AI as a dominant, godlike force eclipsing all other technology.](/assets/images/Michelangelo_-_Creation_of_Adam_(cropped)_meme.jpg)

## The Debate About the Possible

> "When a distinguished but elderly scientist states that something is possible, he is almost certainly right.
>
> When he states that something is impossible, he is very probably wrong."
>
> \- _Arthur C. Clarke's [First Law](https://en.wikipedia.org/wiki/Clarke%27s_three_laws)_

I often let colleagues know that I don't have a great photographic memory for verbal conversations
(and therefore tools like Teams meetings with recordings, transcripts, AI recaps
and the ability to ask questions retroactively about the meeting
are an absolute game-changer and life-saver for me).

My lack of great conversational photographic memory is definitely a "me" thing,
because I have other colleagues who have an almost spooky ability
to remember every single aspect of what was said in a conversationâ€”in many ways,
those types of folks are their own personal Copilot
(whereas for folks like me, I very much need to lean on note-taking and tools and systems to help me stay organized).

I am telling you this because the conversations I _do_ tend to remember the most
are ones tied to emotions that lodge themselves into my amygdala.

And because of that, I have a vivid recollection of what I was thinking and how I felt in 2023.

When ChatGPT became popular, the public discourse was starting to rage about what LLM-based AI could and couldn't do.

Further, people began delving into what AI would be able to do in the future
and what would remain in the realm of "Sci-Fi" (at least, in our lifetimes).

2023, frankly, was a bit of a mentally scary time for critical thinkers,
because any hint of skepticism about what AI could or couldn't do was often met with the retort:

"Well, it's not possible _yet_."

This dead end line of discussion, I felt, wasn't helpful,
and further the pushed notion that AI would solve 'X'â€”where
'X' was in many cases was an already solved problem with existing technologyâ€”often
dismissing all the years of innovation and approaches
that have been around solving problems for people for many, many years;
the humble IF/ELSE deterministic logic has propelled us as a society forward
and shouldn't be tossed out with the bath water.

## What Has Been Possible for a Long Time

![A meme-style still from 2001: A Space Odyssey shows a man seated at a futuristic video console, smiling as he speaks to a child on a screen. Overlaid text on the left reads, "CAN'T YOU THINK OF ANYTHING ELSE YOU WANT FOR YOUR BIRTHDAY? SOMETHING VERY SPECIAL?" Overlaid text on the right, next to the childâ€™s image, reads, "SOMETHING THAT OUTPERFORMS HUMANS ON COMPLEX REASONING BENCHMARKS."](/assets//images/2001-video-call.jpg)

> "The only way of discovering the limits of the possible is to venture a little way past them into the impossible."
>
> \- _Arthur C. Clarke's [Second Law](https://en.wikipedia.org/wiki/Clarke%27s_three_laws)_

Machine learning is [not new](https://en.wikipedia.org/wiki/Machine_learning),
and has existed in some shape or form for many decades,
with papers going back to the [1940s](https://en.wikipedia.org/wiki/Perceptron).

Further, computer science and software engineering are not new,
and have been deployed for many years in many facets of our existence to help solve real problems
and (hopefully, but not always) make our lives better and improve the human condition.

But it always begets the question of what else is possible given the technology we have now,
and will have in the future.

In 2025, I've seen enough of AI the past couple of years to form some opinions.

And so have others.

> "I see no line of sight into AI completely replacing programmers."
>
> \- [Mark Russinovich](https://youtu.be/PjInF4wbmxM?si=Ampik7G3IV3V0naA&t=1231)

I would rather be confident in my opinions and be wrong, and change my mind in the future,
than to forever remain waffle-y about what is possible (or not possible).

I also believe, like Mark, that [hope is not a strategy](https://youtu.be/7FhoUAidsFg?si=GtiAZejmK8c0IwkC),
and I am not going to make decisions based on the pure dream that "One day, AI will handle all of this."

In addition to that, we already have _so much existing technology_ today
that has made what used to be considered "the impossible," possible.

However most of that progress happens by venturing a _little_ bit beyond today's limits;
in stark contrast, we have folks engaging in wild speculation about what _could_ happen _way_ beyond today's limits,
not just about what is possible, but also on what timeframes, and in what ways.

## An Alien From Outer Space ðŸ‘½

![A meme-style image inspired by 2001: A Space Odyssey: a group of early hominids stand and crouch among rocky terrain at sunrise, surrounding a tall black monolith in the center. Overlaid white Impact-style text reads at the top, "SOON YOU WONâ€™T BE MANAGING GATHERERS,"" and at the bottom, "YOU'LL BE MANAGING AGENTSâ€”ER, I MEAN HUNTERS,"" humorously comparing modern AI agent hype to prehistoric evolution.](/assets/images/2001-a-Space-Odyssey-apes-monolith.jpg)

> "Any sufficiently advanced technology is indistinguishable from magic."
>
> \- _Arthur C. Clarke's [Third Law](https://en.wikipedia.org/wiki/Clarke%27s_three_laws)_

This debate about the possible versus the impossible happens in many corners of the internet,
but typically many technical folks who delve into aspects of AI tend to engage in debate the most intensely.

Which begs the question:
Where does this leave the rest of humanity that may not be technical,
and for whom AI is a totally foreign entity?

Many are now trying to (or perhaps, due to fear, in many cases, consciously or unconsciously, trying _not_ to)
wrap their heads around this brand new "thing."

Folks often liken the arrival of modern LLM-based AI to the creation of something analogous to HAL 9000
from the movie _2001: A Space Odyssey_.

However, I often wonder if the arrival of AI is less like HAL,
and more like the Monolith that appears in multiple parts of that movie.

In many ways it feels like an alien technology showed up in our neck of the woods in this Milky Way galaxy,
and everyone is trying to wrap their heads around it.

Another unfortunate byproduct of this is, because AI may feel like "magic" to many people,
they pin all of their hopes and dreams onto the technology, and _hallucinate_ things that AI can and can't do.

The problem is that these human hallucinations aren't just incorrectâ€”they're expensive.
They turn into roadmaps, budgets, and organizational decisions.
And thatâ€™s when the "magic" stops being fun.

And it is also how you get the weirdest part of this moment:
not the technology itself, but the mythology we're building around it.

Which is why I flinch a little bit every time I see a certain phrase making the roundsâ€¦

## Beyond the Infinite â™¾ï¸

![A blurred, dramatic close-up of a wide-eyed astronaut inside a helmet, lit by reflections and glowing lights, with bold white Impact-style text across the center reading, "THIS IS THE WORST AI IS EVER GOING TO BE."](/assets/images/2001-ai-meme.jpg)

> "This is the worst AI is ever going to be."
>
> \- _A trite saying [floating around the internet](https://www.google.com/search?q=this+is+the+worst+ai+is+ever+going+to+be&oq=this+is+the+worst+ai+is+ever+going+to+be&gs_lcrp=EgRlZGdlKgYIABBFGDkyBggAEEUYOTIHCAEQ6wcYQNIBCDU4MzZqMGoxqAIAsAIA&sourceid=chrome&ie=UTF-8)_

Dissecting that annoying line could fill up a whole additional blog post.
(Is it just the models getting better? And purely through more data?
Or is it new type of model techniques?
Or is it techniques we use _around_ the models that get better?
[What do you mean?!](https://giphy.com/gifs/sonypictures-jennifer-lawrence-hot-ones-no-hard-feelings-h58E0JsuK3h3d8B1do))

This utterly useless phrase basically amounts to: "Things improve over time."

Wow.

Beyond the Infinite(ly) stupid.

Everything tends to improve over time, not just AI...

The humble washing machine has improved over time.

I could cite a ton of additional mundane examples here, but you get the idea...

Bringing it back to an example that is less mundane:
Models will improve over time, and model layers and weights are one thing,
but few appreciate the immense amount of work that goes into model _serving_ technologies
like Ray Serve and other libraries that make models like LLMs _actually_ possible to use,
and improvements _will_ be realized in the surrounding technologies
that are all absolutely essential to making AI possible to use,
but may not get their full due, nor the meaningful amount of mind share to discuss openly.

But the most insidious thing about this idiotic phrase is
the simultaneous sense of wonder and awe and existential dread it instills in people
while we are all collectively barreling through the psychological daily onslaught of new AI advancements,
and it is completely uncalled for and unnecessary...

***

If it is truly the worst it is ever going to be, I still at this time find AI immensely useful.

But to find AI useful does not automatically negate the utility of everything else in the technology world
that has come before it, and is still alive and well and being used today.

My coffee maker at home is useful.

This blog post that I am writing right now
and host on GitHub Pages with Cloudflare in front of it is (hopefully) useful,
and fueled by 100% organic pure human thought and creativityâ€”the
only AI help for this post came from creating alt text for the images, to improve accessibility
(which is a great use case for AI).

My [dev machine setup](https://github.com/ryanspletzer/dev-machine-setup) scripts are useful
in saving days setting up a machine by hand,
both for me and for others I know that are using them.
(AI helped me write the latest versions of those,
but AI didn't instill the philosophy of design
nor the essence of simplicity I wanted to achieve in the latest iterations of them,
nor did it provide the years of learning and the acquired taste of what "good" looks like to hone my approach,
nor does it perform the actual setup.)

And in consideration of the time span of all these decades of useful technologies that we've accumulated,
and will continue to accumulate independently of AI,
_we need to be able to have open ways to talk about them_,
and not have those discussions be dismissed out of hand because they are somehow "boring" and not aligned
with the prevailing AI narrative.

For example, to get MCP to work properly,
you have to build up an understanding
of a [web of interrelated IETF specifications around OAuth and adjacent technologies](https://github.com/ryanspletzer/oidc-oauth-spec-graph/blob/main/graph.md),
which to some may feel "boring," but for us engineers,
is essential to produce something that is not a walking security hazard with no auth (or dubious auth)
that vibe coded its way out of its containment zone of Lovable or Replit.

In fact, most of the time I've spent at work with our teams _delivering_ AI for the enterprise involves using
technologies and techniques around data engineering and data science and automation and full-stack software engineering
and cloud infrastructure (and more) that _have nothing to do with AI whatsoever_.

***

Thankfully, I don't think I will be smote by a bolt of lightning
if I write a future blog post that has nothing to do with AI.

(And I won't be smote for this one because there are 36 mentions of the word "AI" in this blog post,
including that most recent one.)

AI didn't create our current set of technologyâ€”rather, our existing technology helped us create AI.

The introduction of AI is additive, not subtractive, to the existing technology we have.

And, coupled with existing technology, AI is more than likely going to help us do amazing things in the future.

With this in mind, maybe, just maybe, the mental model of how we got here, and where we're going,
needs to be thought about a little bit differently,
and should allow more space for more discussion about all types of technology, not just AI.

And perhaps we can try to take some things a little less seriously and remember to have a
[little bit](https://www.ocregister.com/wp-content/uploads/migration/mnb/mnbih3-b781115628z.120130524122745000ga11e4tlo.3.jpg?w=620)
of [fun](https://www.youtube.com/watch?v=F9-zi-qKg8I) along the way, tooâ€”so in the spirit of fun,
let's flip this script:

![A meme-style reinterpretation of Michelangelo's The Creation of Adam. On the left, Adam reclines with the label "AI" in bold white text. On the right, God reaches out from a cloud of figures labeled "THE REST OF TECHNOLOGY." Their outstretched hands nearly touch, parodying the original composition to suggest AI is not above the rest of technology.](/assets/images/Michelangelo_-_Creation_of_Adam_(cropped)_meme_reversed.jpg)
